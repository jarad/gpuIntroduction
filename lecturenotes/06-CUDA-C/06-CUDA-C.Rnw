\documentclass{article}

\hoffset = 0pt
\voffset = 0pt
\footskip = 75pt

\usepackage[landscape]{geometry}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{color}
\usepackage{listings}
%\usepackage{Sweave}
%\usepackage{SASnRdisplay}

\providecommand{\beq}{\begin{equation*}}
\providecommand{\eeq}{\end{equation*}}
\providecommand{\bs}{\backslash}
\providecommand{\e}{\varepsilon}
\providecommand{\E}{\ \exists \ }
\providecommand{\all}{\ \forall \ }
\providecommand{\Rt}{\Rightarrow}
\providecommand{\rt}{\rightarrow}
\providecommand{\vc}[1]{\boldsymbol{#1}}
\providecommand{\N}{\mathbb{N}}
\providecommand{\Q}{\mathbb{Q}}
\providecommand{\R}{\mathbb{R}}
\providecommand{\C}{\mathbb{C}}
\providecommand{\Z}{\mathbb{Z}}
\providecommand{\Qn}{\mathbb{Q}^n}
\providecommand{\Rn}{\mathbb{R}^n}
\providecommand{\Cn}{\mathbb{C}^n}
\providecommand{\Zn}{\mathbb{Z}^n}
\providecommand{\Qk}{\mathbb{Q}^k}
\providecommand{\Rk}{\mathbb{R}^k}
\providecommand{\Ck}{\mathbb{C}^k}
\providecommand{\Zk}{\mathbb{Z}^k}
\providecommand{\ov}[1]{\overline{#1}}
\providecommand{\lmu}[1]{\lim_{#1 \rightarrow \infty}}
\providecommand{\lmd}[1]{\lim_{#1 \rightarrow -\infty}}
\providecommand{\lm}[2]{\lim_{#1 \rightarrow #2}}
\providecommand{\nv}{{}^{-1}}
\providecommand{\aut}[1]{\text{Aut}{ \ #1}}
\providecommand{\inn}[1]{\text{Inn}{ \ #1}}
\providecommand{\cj}[1]{\overline{#1}}
\providecommand{\wh}[1]{\widehat{#1}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}

\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}

\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}

\bibliographystyle{plain}

\providecommand{\pset}{1}   %PUT PROBLEM SET NUMBRER HERE
\renewcommand{\labelenumi}{\alph{enumi}.} %controls enumerating style
\renewcommand{\labelenumii}{\roman{enumii}.} 
  
\setcounter{section}{\pset}

\begin{document}
\begin{flushleft}

\Huge
\begin{center}
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
{\bf INTRODUCTION TO PROGRAMMING IN CUDA C}
\end{center} $\quad$ \newline

\LARGE

\begin{center}
Will Landau, Prof. Jarad Niemi
\end{center}

\newpage

\Huge
\begin{center}
{\bf OUTLINE} 
\end{center} $\quad$ \newline \Large
\begin{itemize}
\item Defining and calling kernels and other device functions
\item CPU-GPU communication
\item Built-in CUDA C variables
\item Synchronizing threads
\item Respecting the SIMD paradigm
\end{itemize} $\quad$ \newline

Featured examples: \newline
\begin{itemize}
\item {\tt skeleton.cu}
\item {\tt simple.cu}
\item {\tt vector\_sums.cu}
\item {\tt pairwise\_sum.cu}
\item {\tt sisd.cu}
\end{itemize}


\newpage

\Huge
\begin{center}
{\bf BASIC C PROGRAM}
\end{center} $\quad$ \newline

% JBN: in the future I would suggest using a verbatim environment for code
%\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{1} \newpage

\begin{lstlisting}
#include <stdio.h>

int main(){
  printf(''Hello, World!\n");
  return 0;
}
\end{lstlisting} $\quad$ \newline

\newpage
\Huge
\begin{center}
{\bf BASIC CUDA C PROGRAM}
\end{center} $\quad$ \newline

% JBN: the __global__ prefix doesn't say to me "do this on the GPU" but rather "only run this function on the GPU"
%      the kernel<<<1,1>>> says "do this on the GPU"
\setkeys{Gin}{width=0.7\textwidth} \includegraphics[scale=0.25,angle=0]{2a} \newpage

%\begin{lstlisting}
%#include <stdio.h>

%__global__ void kernel(){
%}

%int main(){
 % kernel<<<1,1>>>();
%  printf("Hello, World!\n");
 % return 0;
%}
%\end{lstlisting}


\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{2b} \newpage

\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{2c} \newpage

\Large
\begin{verbatim} __global__: Call from CPU and run only on GPU.

__device__: Call from GPU and run only on GPU.
                               (More specifically, call only from within 
                                a __global__ or another __device__ function.)

__host__: Call from CPU and run only on CPU.
                                (i.e., a traditional C function.)
 \end{verbatim}


\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{fkeywords} \newpage
\LARGE

\begin{verbatim}
#include <stdio.h>

__device__ int dev1( void ){
}

__device__ int dev2( void ){
}

__global__ void kernel ( void ) {
  dev1();
  dev2();
}

int main ( void ) {
  kernel<<<1, 1>>>();
  printf( "Hello, World!\n" );
  return 0;
}
\end{verbatim}

\newpage

\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{2d} \newpage



\Huge
\begin{center}
{\bf GPU PARALLELISM}
\end{center}  \huge
\begin{enumerate}[1. ]
\item The CPU sends a CPU-to-GPU command called a {\bf kernel} to a single GPU core.\newline
\item The GPU core multitasks to execute the command: \newline
\begin{enumerate}[a. ]
\item The GPU makes $B \cdot T$ {\color{blue} copies} of the kernel's code, and then runs all those copies simultaneously. Those parallel copies are called {\bf threads}.  \newline
\item The $B \cdot T$ threads are partitioned into $B$ groups, called {\bf blocks}, of $T$ threads each. \newline
\item The sum total of all the threads from a kernel call is a {\bf grid}. 
\end{enumerate} 
\end{enumerate}

\newpage

\setkeys{Gin}{width=.65\textwidth} \includegraphics[scale=0.25,angle=0]{imng.jpg}

\newpage

\Huge
\begin{center}
{\bf NOW BACK TO THE STUFF IN ANGLE BRACKTES...}
\end{center} $\quad$ \newline


\setkeys{Gin}{width=.8\textwidth} \includegraphics[scale=0.25,angle=0]{2e} \newpage


\Huge
\begin{center}
{\bf Here, the GPU runs {kernel()} one time:}
\end{center} $\quad$ \newline
\begin{verbatim}
#include <stdio.h>

__global__ void kernel ( void ) {
}

int main ( void ) {
  kernel<<<1,1>>>();
  printf( "Hello, World!" \n" )
  return 0;
}\end{verbatim} \newpage



\Huge
\begin{center}
{\bf Here, the GPU runs {kernel()} 5 times:}
\end{center} $\quad$ \newline
\begin{verbatim}
#include <stdio.h>

__global__ void kernel ( void ) {
}

int main ( void ) {
  kernel<<<5,1>>>();
  printf( "Hello, World!" \n" )
  return 0;
} \end{verbatim} \newpage

\Huge
\begin{center}
{\bf Here, the GPU runs {kernel()} 5 times:}
\end{center} $\quad$ \newline
\begin{verbatim}
#include <stdio.h>

__global__ void kernel ( void ) {
}

int main ( void ) {
  kernel<<<1,5>>>();
  printf( "Hello, World!" \n" )
  return 0;
} \end{verbatim} \newpage


\Huge
\begin{center}
{\bf Here, the GPU runs {kernel()} 20 times:}
\end{center} $\quad$ \newline
\begin{verbatim}
#include <stdio.h>

__global__ void kernel ( void ) {
}

int main ( void ) {
  kernel<<<4,5>>>();
  printf( "Hello, World!" \n" )
  return 0;
} \end{verbatim}\newpage


\newpage

\Huge
\begin{center}
{\bf \LARGE BEYOND HELLO WORLD: {\tt skeleton.cu}}
\end{center} $\quad$ \newline \normalsize
\begin{verbatim}
#include <stdio.h> 
#include <stdlib.h> 
#include <cuda.h>
#include <cuda_runtime.h> 

__global__ void some_kernel(...){...}

int main (void){ 
  // Declare all variables.
  ...
  // Dynamically allocate host memory.
  ...
  // Dynamically allocate device memory.
  ...
  // Write to host memory.
  ... 
  // Copy host memory to device memory.
  ...
  // Execute kernel on the device.
  some_kernel<<< num_blocks, num_theads_per_block >>>(...);
  
  // Write device memory back to host memory.
  ...
  // Free dynamically-allocated host memory
  ...
  // Free dynamically-allocated device memory    
  ...
}
\end{verbatim} $\quad$ \newline

\newpage

\LARGE
\begin{center}
{\bf PASSING DATA TO AND FROM THE GPU: simple.cu}
\end{center}  \Large

% JBN: perhaps decrease font size to get the code all on the same page
\begin{verbatim}                                                                                                         
#include <stdio.h>
#include <stdlib.h>
#include <cuda.h>
#include <cuda_runtime.h> 

__global__ void colonel(int *a_d){
  *a_d = 2;
}

int main(){

  int a = 0, *a_d;
  
  cudaMalloc((void**) &a_d, sizeof(int));
  cudaMemcpy(a_d, &a, sizeof(int), cudaMemcpyHostToDevice);

  colonel<<<100,100>>>(a_d); 
  
  cudaMemcpy(&a, a_d, sizeof(int), cudaMemcpyDeviceToHost);

  printf("a = %d\n", a);
  cudaFree(a_d);

}
\end{verbatim} $\quad$ \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{simple1} 

\newpage

\Huge
\begin{center}
{\bf BUILT-IN CUDA C VARIABLES}
\end{center}  $\quad$ \newline

\Large 

\begin{itemize}
\item {\bf maxThreadsPerBlock}: exactly that: 1024 on an impact1 core. \newline
\end{itemize}

Also, within a kernel call with $B$ blocks and $T$ threads per block, you can use: \newline

\begin{itemize}
\item{\bf blockIdx.x}: the block ID corresponding to the current thread, an integer from 0 to $B - 1$ inclusive. \newline

\item{\bf threadIdx.x}: the thread ID of the current thread within its block, an integer from 0 to $T - 1$ inclusive. \newline

\item{\bf gridDim.x}: $B$, the number of blocks in the grid. \newline

\item {\bf blockDim.x}: $T$, the number of threads per block. \newline
\end{itemize}
\newpage


\Huge
\begin{center}
{\bf VECTOR ADDITION: {\tt vectorsums.cu}}
\end{center} $\quad$ \newline \large

\begin{verbatim}
#include <stdio.h>
#include <stdlib.h>
#include <cuda.h>
#include <cuda_runtime.h> 

#define N 10

__global__ void add(int *a, int *b, int *c){
  int bid = blockIdx.x;
  if(bid < N)
    c[bid] = a[bid] + b[bid];
}

int main(void) {
  int i, a[N], b[N], c[N];
  int *dev_a, *dev_b, *dev_c;

  cudaMalloc((void**) &dev_a, N*sizeof(int));
  cudaMalloc((void**) &dev_b, N*sizeof(int));
  cudaMalloc((void**) &dev_c, N*sizeof(int));

  for(i=0; i<N; i++){
    a[i] = -i;
    b[i] = i*i;
  }

  cudaMemcpy(dev_a, a, N*sizeof(int), cudaMemcpyHostToDevice);
  cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice);

  add<<<N,1>>>(dev_a, dev_b, dev_c);

  cudaMemcpy(c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost);

  printf("\na + b = c\n");
  for(i = 0; i<N; i++){
    printf("%5d + %5d = %5d\n", a[i], b[i], c[i]);
  }

  cudaFree(dev_a);
  cudaFree(dev_b);
  cudaFree(dev_c);
}
\end{verbatim} $\quad$ \newpage

\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{vectorsums} 



\newpage
\Huge
\begin{center}
{\bf SYNCHRONIZING THREADS}
\end{center} $\quad$ \newline

Within a kernel call, whenever you need to synchronize all the threads in the current block, call: \newline \newline

\begin{verbatim}
__syncthreads();
\end{verbatim} $\quad$ \newline


\newpage

\Huge
\begin{center}
{\bf EXAMPLE: A RETURN TO THE PAIRWISE SUM}
\end{center} $\quad$ \newline

Let's take the pairwise sum of the vector, (5, 2, -3, 1, 1, 8, 2, 6): \newpage

\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{pv1} \newpage
\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{pv2} \newpage
\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{pv3} \newpage
\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{pv} \newpage
\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{pv5} \newpage
\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{6} \newpage
\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{7} \newpage
\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{8} \newpage
\setkeys{Gin}{width=1\textwidth} \includegraphics[scale=0.25,angle=0]{9} \newpage



\Huge
\begin{center}
{\bf A RIGOROUS DESCRIPTION OF THE PAIRWISE SUM}
\end{center} \LARGE


Suppose you have a vector $X_0 = (x_{(0,0)}, x_{(0,2)}, \ldots, x_{(0,n-1)})$, where $n = 2^m$ for some $m>0$. \newline

 Compute $\sum_{i = 1}^n x_{(0,i)}$ in the following way:  \newline

\begin{enumerate}[1. ]
\item Create a new vector: $X_1 = ( \underbrace{x_{(0, \ 0)} + x_{(0, \ n/2)}}_{x_{(1, \ 0)}}, \  \underbrace{x_{(0,1)} + x_{(0, \ n/2 + 1)}}_{x_{(1,\ 1)}}, \ \ldots, \underbrace{x_{(0, \ n/2-1)} + x_{(0, \ n - 1)}}_{x_{(1, \ n/2 - 1)}})$

\item Create another new vector: $X_2 = ( \underbrace{x_{(1, \ 0)} + x_{(1, \ n/4)}}_{x_{(2, \ 0)}}, \  \underbrace{x_{(1,\ 1)} + x_{(1, \ n/4 + 1)}}_{x_{(2, \ 1)}}, \ \ldots, \underbrace{x_{(1, n/4-1)} + x_{(1, \ n/2 - 1)}}_{x_{(2, \ n/4 - 1)}})$
\item Continue this process until you get a singleton vector: $X_{m} =  ( \underbrace{x_{(m - 1, 0)} +  x_{(m - 1, 1)}}_{x_{(m, 0)}}  ) $
\end{enumerate} $\quad$ \newline
Notice: $\sum_{i = 1}^n x_{(0,i)} = x_{(m, 0)}$




\newpage
\Huge
\begin{center}
{\bf PARALLELIZING THE PAIRWISE SUM}
\end{center} $\quad$ \newline

Spawn one grid with a single block and $n/2$ threads ($n = 2^m$). Starting with $i = 1$, do the following: \newline

\begin{enumerate}[1. ]
\item Set \text{offset} = $n/2^i$. 
\item Assign thread $j$ to compute: 
\begin{align*}
x_{(i,j)} = x_{(i-1, \ j)} + x_{(i-1,\  j + \text{offset})}
\end{align*} for $j = 0, 2, \cdots, \text{offset} - 1$.
\item Wait until all the above $\frac{n}{2^i}$ threads have completed step 2.
\item Integer divide offset by 2. Repeat if offset $> 0$.  
\end{enumerate}



\newpage

\Huge
\begin{center}
{\bf PAIRWISE SUM: pairwise\_sum.cu}
\end{center} $\quad$ \newline \large

\begin{verbatim}
#include <stdio.h> 
#include <stdlib.h> 
#include <math.h>
#include <cuda.h>
#include <cuda_runtime.h> 

/*
 * This program computes the sum of the elements of 
 * vector v using the pairwise (cascading) sum algorithm.
 */

#define N 8 // length of vector v. MUST BE A POWER OF 2.

// Fill the vector v with n random floating point numbers.
void vfill(float* v, int n){
  int i;
  for(i = 0; i < n; i++){
    v[i] = (float) rand() / RAND_MAX;
  }
}

// Print the vector v.
void vprint(float* v, int n){
  int i;
  printf("v = \n");
  for(i = 0; i < n; i++){
    printf("%7.3f\n", v[i]);
  }
  printf("\n");
}

// Pairwise-sum the elements of vector v and store the result in v[0]. 
__global__ void psum(float* v){ 
  int t = threadIdx.x; // Thread index.
  int n = blockDim.x / 2; // Should be half the length of v.

  while (n != 0) {
    if(t < n)
      v[t] += v[t + n];  
    __syncthreads();    
    n /= 2; 
  }
}

int main (void){ 
  if(N % 2){
    printf("\nERROR: N is not a power of 2. Exiting.\n");
    exit(1);
  }

  float *v_h, *v_d; // host and device copies of our vector, respectively
  
  // dynamically allocate memory on the host for v_h
  v_h = (float*) malloc(N * sizeof(*v_h)); 
  
  // dynamically allocate memory on the device for v_d
  cudaMalloc ((float**) &v_d, N *sizeof(*v_d)); 
  
  // Fill v_h with N random floating point numbers.
  vfill(v_h, N);
  
  // Print v_h to the console
  vprint(v_h, N);
  
  // Write the contents of v_h to v_d
  cudaMemcpy( v_d, v_h, N * sizeof(float), cudaMemcpyHostToDevice );
  
  // Compute the pairwise sum of the elements of v_d and store the result in v_d[0].
  psum<<< 1, N/2 >>>(v_d);
  
  // Write the pairwise sum, v_d[0], to v_h[0].
  cudaMemcpy(v_h, v_d, sizeof(float), cudaMemcpyDeviceToHost );
  
  // Print the pairwise sum.
  printf("Pairwise sum = %7.3f\n", v_h[0]);
  
  // Free dynamically-allocated host memory
  free(v_h);

  // Free dynamically-allocated device memory    
  cudaFree(&v_d);
}
\end{verbatim} $\quad$ \newpage

\newpage

\Huge
\begin{center}
{\bf THE SIMD PARADIGM}
\end{center} $\quad$ \newline

{\bf SIMD}: Single Instruction Multiple Data \newline

Each thread uses the same code, but applies it to different data.  \newline

Try to respect this paradigm in you code. If multiple threads access the same data, problems could arise.

\newpage
\Huge
\begin{center}
{\bf EXAMPLE: {\tt sisd.cu}}
\end{center} \large

\begin{verbatim}
#include <stdio.h>
#include <stdlib.h>
#include <cuda.h>
#include <cuda_runtime.h> 

__global__ void colonel(int *a_d){
  *a_d = blockDim.x * blockIdx.x + threadIdx.x;
}

int main(){

  int a = 0, *a_d;
  
  cudaMalloc((void**) &a_d, sizeof(int));
  cudaMemcpy(a_d, &a, sizeof(int), cudaMemcpyHostToDevice);

  colonel<<<4,5>>>(a_d); 
  
  cudaMemcpy(&a, a_d, sizeof(int), cudaMemcpyDeviceToHost);

  printf("a = %d\n", a);
  cudaFree(a_d);

}
\end{verbatim} $\quad$ \newline

{\color{red} If we run this program, what will be the output?} \newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{sisd} \newline \newline

\huge
All the threads are trying to write to the same variable at the same time.  \newline

Hence, the value of {\tt a} will correspond to the thread that finished last.

\newpage

\Huge
\begin{center}
{\bf OUTLINE} 
\end{center} $\quad$ \newline \Large
\begin{itemize}
\item Defining and calling kernels and other device functions
\item CPU-GPU communication
\item Built-in CUDA C variables
\item Synchronizing threads
\item Respecting the SIMD paradigm
\end{itemize} $\quad$ \newline

Featured examples: \newline
\begin{itemize}
\item {\tt skeleton.cu}
\item {\tt simple.cu}
\item {\tt vector\_sums.cu}
\item {\tt pairwise\_sum.cu}
\item {\tt sisd.cu}
\end{itemize}


\newpage
\Huge
\begin{center}
{\bf LECTURE SERIES MATERIALS}
\end{center} $\quad$ \newline
\huge
These lecture slides, a tentative syllabus for the whole lecture series, and code are available at: \newline

\begin{center}
 https://github.com/wlandau/gpu. 
\end{center} $\quad$ \newline


After logging into you home directory on impact1, type: \newline

\begin{verbatim}
        git clone https://github.com/wlandau/gpu
\end{verbatim} $\quad$ \newline

into the command line to download all the course materials.

\newpage

\Huge
\begin{center}
{\bf REFERENCES}
\end{center} $\quad$ \newline

David B. Kirk and Wen-mei W. Hwu. ``Programming Massively Parallel Processors: a Hands-on Approach." Morgan Kaufman, 2010. \newline

J. Sanders and E. Kandrot. {\it CUDA by Example}. Addison-Wesley, 2010. \newline


\end{flushleft}
\end{document}
