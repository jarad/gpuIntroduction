\documentclass{article}

\hoffset = 0pt
\voffset = 0pt
\footskip = 75pt

\usepackage[landscape]{geometry}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}
\usepackage{hyperref}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{color}

\usepackage{listings}
\usepackage{color}
 
 \hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=blue
}

 
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
 
\lstset{ %
  language=C,                % the language of the code
  basicstyle=\Large,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{white},  % the style that is used for the line-numbers
%  stepnumber=2,                   % the step between two line-numbers. If it's 1, each line 
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},      % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=n,                   % sets the caption-position 
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  title=\lstname,                   % show the filename of files included with \lstinputlisting;
                                  % also try caption instead of title
  keywordstyle=\color{blue},          % keyword style
  commentstyle=\color{dkgreen},       % comment style
  stringstyle=\color{mauve},         % string literal style
  escapeinside={\%*}{*)},            % if you want to add LaTeX within your code
  morekeywords={*,...}               % if you want to add more keywords to the set
}

\captionsetup{labelformat=empty,labelsep=none}


\providecommand{\beq}{\begin{equation*}}
\providecommand{\eeq}{\end{equation*}}
\providecommand{\bs}{\backslash}
\providecommand{\e}{\varepsilon}
\providecommand{\E}{\ \exists \ }
\providecommand{\all}{\ \forall \ }
\providecommand{\Rt}{\Rightarrow}
\providecommand{\rt}{\rightarrow}
\providecommand{\vc}[1]{\boldsymbol{#1}}
\providecommand{\N}{\mathbb{N}}
\providecommand{\Q}{\mathbb{Q}}
\providecommand{\R}{\mathbb{R}}
\providecommand{\C}{\mathbb{C}}
\providecommand{\Z}{\mathbb{Z}}
\providecommand{\Qn}{\mathbb{Q}^n}
\providecommand{\Rn}{\mathbb{R}^n}
\providecommand{\Cn}{\mathbb{C}^n}
\providecommand{\Zn}{\mathbb{Z}^n}
\providecommand{\Qk}{\mathbb{Q}^k}
\providecommand{\Rk}{\mathbb{R}^k}
\providecommand{\Ck}{\mathbb{C}^k}
\providecommand{\Zk}{\mathbb{Z}^k}
\providecommand{\ov}[1]{\overline{#1}}
\providecommand{\lmu}[1]{\lim_{#1 \rightarrow \infty}}
\providecommand{\lmd}[1]{\lim_{#1 \rightarrow -\infty}}
\providecommand{\lm}[2]{\lim_{#1 \rightarrow #2}}
\providecommand{\nv}{{}^{-1}}
\providecommand{\aut}[1]{\text{Aut}{ \ #1}}
\providecommand{\inn}[1]{\text{Inn}{ \ #1}}
\providecommand{\cj}[1]{\overline{#1}}
\providecommand{\wh}[1]{\widehat{#1}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}

\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}

\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}

\bibliographystyle{plain}

\providecommand{\pset}{1}   %PUT PROBLEM SET NUMBRER HERE
\renewcommand{\labelenumi}{\alph{enumi}.} %controls enumerating style
\renewcommand{\labelenumii}{\roman{enumii}.} 
  
\setcounter{section}{\pset}

\begin{document}
\begin{flushleft}

\Huge
\begin{center}
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
{\bf CUDA C: RACE CONDITIONS AND ATOMICS}
\end{center} $\quad$ \newline

\LARGE

\begin{center}
Will Landau, Prof. Jarad Niemi
\end{center}

\newpage

\Huge
\begin{center}
{\bf OUTLINE}
\end{center} $\quad$ \newline \Large

\begin{itemize}
\item Overview of race conditions and atomics
\item CUDA C built-in atomic functions
\item Locks and mutex
\item Warps
\item Appendix: the atomic dot product
\end{itemize} $\quad$ \newline

Featured examples: \newline

\begin{itemize}
\item {\tt dot\_product\_atomic\_builtin.cu}
\item {\tt dot\_product\_atomic\_lock.cu}
\item {\tt race\_condition.cu}
\item {\tt race\_condition\_fixed.cu}
\item {\tt blockCounter.cu}
\end{itemize} 



\newpage

\Huge
\begin{center}
{\bf RACE CONDITIONS AND ATOMICS}
\end{center} $\quad$ \newline

Consider the following GPU operation on integer {\tt x}, which is stored in global memory: \newline



\begin{verbatim}
                     x++;
\end{verbatim} $\quad$ \newline

which tells the GPU to do 3 things...
\newpage

\begin{verbatim}
                     x++;
\end{verbatim} $\quad$ \newline


\begin{enumerate}[1. ]
\item Read the value stored in x.
\item Add 1 to the value read in step 1.
\item Write the result back to x.
\end{enumerate}


\newpage

Say we need threads A and B to increment x. We want: \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{1} \newpage

but we might get: \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{2} 

\newpage


\Huge
\begin{center}
{\bf EXAMPLE: race\_condition.cu}
\end{center} $\quad$ \newline \large

\begin{lstlisting}[language = C]
#include <stdio.h>
#include <stdlib.h>
#include <cuda.h>
#include <cuda_runtime.h> 

__global__ void colonel(int *a_d){
  *a_d += 1;
}

int main(){

  int a = 0, *a_d;
  
  cudaMalloc((void**) &a_d, sizeof(int));
  cudaMemcpy(a_d, &a, sizeof(int), cudaMemcpyHostToDevice);

  float   elapsedTime;
  cudaEvent_t start, stop;
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord( start, 0 );

  colonel<<<1000,1000>>>(a_d); 
  
  cudaEventRecord( stop, 0 );
  cudaEventSynchronize( stop );
  cudaEventElapsedTime( &elapsedTime, start, stop );
  cudaEventDestroy( start );
  cudaEventDestroy( stop );
  printf("GPU Time elapsed: %f seconds\n", elapsedTime/1000.0);
  
  
  cudaMemcpy(&a, a_d, sizeof(int), cudaMemcpyDeviceToHost);

  printf("a = %d\n", a);
  cudaFree(a_d);

}
\end{lstlisting} $\quad$ \newline

\newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{race.png} \newline \newline

\Huge

Since we started with {\tt a} at 0, we should have gotten {\tt a} = $1000 \cdot 1000$ = 1,000,000.



\newpage


{\bf Race Condition:} A computational hazard that arises when the results of a program depend on the timing of uncontrollable events, such as threads. \newline

{\bf Atomic Operation:} A command that is executed one thread at a time, thus avoiding a race condition. \newline

To avoid the race condition in our example, we atomically add 1 to {\tt *a\_d}: \newline

\begin{verbatim}
               atomicAdd( a_d, 1 );
\end{verbatim} $\quad$ \newline

instead of using {\tt *a\_d += 1;}

\newpage

\Huge
\begin{center}
{\bf EXAMPLE: race\_condition\_fixed.cu}
\end{center} $\quad$ \newline \large

\begin{lstlisting}[language = C]
#include <stdio.h>
#include <stdlib.h>
#include <cuda.h>
#include <cuda_runtime.h> 

__global__ void colonel(int *a_d){
  atomicAdd( a_d, 1 );
}

int main(){

  int a = 0, *a_d;
  
  cudaMalloc((void**) &a_d, sizeof(int));
  cudaMemcpy(a_d, &a, sizeof(int), cudaMemcpyHostToDevice);

  float   elapsedTime;
  cudaEvent_t start, stop;
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord( start, 0 );

  colonel<<<1000,1000>>>(a_d); 
  
  cudaEventRecord( stop, 0 );
  cudaEventSynchronize( stop );
  cudaEventElapsedTime( &elapsedTime, start, stop );
  cudaEventDestroy( start );
  cudaEventDestroy( stop );
  printf("GPU Time elapsed: %f seconds\n", elapsedTime/1000.0);
  
  
  cudaMemcpy(&a, a_d, sizeof(int), cudaMemcpyDeviceToHost);

  printf("a = %d\n", a);
  cudaFree(a_d);

}
\end{lstlisting} $\quad$ \newline


\setkeys{Gin}{width=1\textwidth} \includegraphics{race2.png} \newline \newline

\huge
We got the right answer, but the execution time was 100 times longer? Why?

\newpage

\Huge
\begin{center}
{\bf THINGS TO NOTE}
\end{center} $\quad$ \newline

\begin{itemize}
\item The code slowed down because that the additions happened sequentially instead of simultaneously. 
\item If you're using any of the above functions in your code, compile with the flag, {\tt -arch sm\_20} as above. (Atomics support floating point operations only for  CUDA ``compute capability" 2.0. and above.) 
\end{itemize}
\newpage

\huge
\begin{center}
{\bf LIST OF CUDA C BUILT-IN ATOMIC FUNCTIONS}
\end{center} $\quad$ \newline \LARGE

atomicAdd() \newline
atomicSub()  \newline
atomicMin()  \newline 
atomicMax() \newline
atomicInc() \newline
atomicDec() \newline
atomicExch() \newline
atomicCAS() \newline

For documentation, refer to the CUDA C Programming Guide (\url{http://developer.download.nvidia.com/compute/DevZone/docs/html/C/doc/CUDA_C_Programming_Guide.pdf}).  

\newpage

% JBN: These functions both return and store the value at the address. Why?

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{3}  \newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{4} 
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{5} 
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{6}  \newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{7} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{8} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{9} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{10} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{11} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{12} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{13} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{14} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{15} \newpage






\newpage


\Huge
\begin{center}
{\bf LOCKS}
\end{center} $\quad$ \newline

{\bf Lock}: a mechanism in parallel computing that forces an entire segment of code to be executed atomically.  \newline

{\bf mutex}: short for ``mutual exclusion", the idea behind locks: while a thread is running code inside a lock, it blocks all other threads from running the code.

\newpage

\Huge
\begin{center}
{\bf THE CONCEPT}
\end{center} $\quad$ \newline


\begin{lstlisting}
__global__ void someKernel( void ){

  // some parallel code

   Lock mylock;   
   mylock.lock();
   
   // some sequential code
   
   mylock.unlock();
   
   // some parallel code
}
\end{lstlisting}



\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{lockloop} \newpage

\newpage \Large
lock.h: \newline
\setkeys{Gin}{width=.8\textwidth} \includegraphics[scale=0.25,angle=0]{lock} \newpage

\large
Now, let's look at the lock function:

\begin{verbatim}
__device__ void lock( void ) {
    while( atomicCAS( mutex, 0, 1 ) != 0 );
}
\end{verbatim} $\quad$ \newline

In pseudo-code:

\begin{verbatim}
__device__ void lock( void ) {
  repeat{
    do atomically{
      
      if(mutex == 0){
        mutex = 1;
        return_value = 0;
      }
      
      else if(mutex == 1){
        return_value = 1;
      }
      
    } // do atomically
    
    if(return_value = 0)
      exit loop;
    
  } // repeat
}// lock
\end{verbatim} $\quad$ \newpage


\LARGE
\begin{center}
{\bf EXAMPLE: COUNTING THE NUMBER OF BLOCKS}
\end{center} 

\Large
Compare these two kernels, both of which attempt to count the number of spawned blocks: \newline

\begin{lstlisting}[language = C]
__global__ void blockCounterUnlocked( int *nblocks ){
   if(threadIdx.x == 0){
    *nblocks = *nblocks + 1;
  }
}

__global__ void blockCounter1( Lock lock, int *nblocks ){
  if(threadIdx.x == 0){
    lock.lock();
    *nblocks = *nblocks + 1;
    lock.unlock();
  }
}
\end{lstlisting} $\quad$ \newline \color{blue}
Which one gives us the correct answer? \newline
Which one is faster?
\color{black}
\newpage

\Huge
\begin{center}
{\bf blockCounter.cu}
\end{center} $\quad$ \newline
\Large
\begin{verbatim}
#include "../common/lock.h"
#define NBLOCKS_TRUE 512
#define NTHREADS_TRUE 512 * 2

__global__ void blockCounterUnlocked( int *nblocks ){
   if(threadIdx.x == 0){
    *nblocks = *nblocks + 1;
  }
}

__global__ void blockCounter1( Lock lock, int *nblocks ){
  if(threadIdx.x == 0){
    lock.lock();
    *nblocks = *nblocks + 1;
    lock.unlock();
  }
}



int main(){
  int nblocks_host, *nblocks_dev;
  Lock lock;
  float elapsedTime;
  cudaEvent_t start, stop;
 
  cudaMalloc((void**) &nblocks_dev, sizeof(int));
  

  //blockCounterUnlocked:

  nblocks_host = 0;
  cudaMemcpy( nblocks_dev, &nblocks_host, sizeof(int), cudaMemcpyHostToDevice );
  
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord( start, 0 );
  
  blockCounterUnlocked<<<NBLOCKS_TRUE, NTHREADS_TRUE>>>(nblocks_dev);

  cudaEventRecord( stop, 0 );
  cudaEventSynchronize( stop );
  cudaEventElapsedTime( &elapsedTime, start, stop );

  cudaEventDestroy( start );
  cudaEventDestroy( stop ); 

  cudaMemcpy( &nblocks_host, nblocks_dev, sizeof(int), cudaMemcpyDeviceToHost );
  printf("blockCounterUnlocked <<< %d, %d >>> () counted %d blocks in %f ms.\n", 
        NBLOCKS_TRUE,
        NTHREADS_TRUE,
        nblocks_host,
        elapsedTime);
        
        
  //blockCounter1:

  nblocks_host = 0;
  cudaMemcpy( nblocks_dev, &nblocks_host, sizeof(int), cudaMemcpyHostToDevice );
  
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord( start, 0 );
  
  blockCounter1<<<NBLOCKS_TRUE, NTHREADS_TRUE>>>(lock, nblocks_dev);

  cudaEventRecord( stop, 0 );
  cudaEventSynchronize( stop );
  cudaEventElapsedTime( &elapsedTime, start, stop );

  cudaEventDestroy( start );
  cudaEventDestroy( stop ); 

  cudaMemcpy( &nblocks_host, nblocks_dev, sizeof(int), cudaMemcpyDeviceToHost );
  printf("blockCounter1 <<< %d, %d >>> () counted %d blocks in %f ms.\n", 
        NBLOCKS_TRUE,
        NTHREADS_TRUE,
        nblocks_host,
        elapsedTime);      
                   
  cudaFree(nblocks_dev); 
}

\end{verbatim}

\newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{locks} \newpage

\huge
\begin{center}
{\bf WITH MORE THAN 1 THREAD PER BLOCK, THIS KERNEL WILL MAKE YOUR PROGRAM PAUSE INDEFINITELY}
\end{center} $\quad$ \newline

 \huge
\begin{verbatim}
__global__ void blockCounter2( Lock lock, int *nblocks ){
  lock.lock();
  if(threadIdx.x == 0){
    *nblocks = *nblocks + 1 ;
  }
  lock.unlock();
}
\end{verbatim}

\newpage

\Huge
\begin{center}
{\bf WHY? BECAUSE OF WARPS!}
\end{center} $\quad$ \newline

Each block is divided into groups of 32 threads called warps. \newline

{\bf Warp:} a group of 32 threads that execute together in lockstep: that is, all threads in the warp synchronize after every single step.  \newline

{\color{blue} Imagine that a warp is saturated with calls to {\tt \_\_synchThreads()}.}

\newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{diffwarp} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{samewarp} \newpage
\large
Now, let's look at the lock function again:

\begin{verbatim}
__device__ void lock( void ) {
    while( atomicCAS( mutex, 0, 1 ) != 0 );
}
\end{verbatim} $\quad$ \newline

In pseudo-code:

\begin{verbatim}
__device__ void lock( void ) {
  repeat{
    do atomically{
      
      if(mutex == 0){
        mutex = 1;
        return_value = 0;
      }
      
      else if(mutex == 1){
        return_value = 1;
      }
      
    } // do atomically
    
    if(return_value = 0)
      exit loop;
    
  } // repeat
}// lock
\end{verbatim} $\quad$ \newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{lockloop1} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{lockloop2}  \newpage

\Huge
\begin{center}
{\bf KEEP TO THE SINGLE INSTRUCTION MULTIPLE DATA PARADIGM AS MUCH AS POSSIBLE}
\end{center} $\quad$ \newline

\begin{itemize}
\item Race conditions are difficult to debug.
\item Atomics are sequential, and therefore slow.
\item Locks are tricky, and may cause your programs to pause indefinitely.
\end{itemize} $\quad$ \newline

% JBN: I think the last point that should be made is that an attempt should be made to eliminate locks and atomics in designing parallel algorithms. The point of this talk is to use them when they are absolutely necessary.

\newpage

\Huge
\begin{center}
{\bf OUTLINE}
\end{center} $\quad$ \newline \Large

\begin{itemize}
\item Race conditions and atomics
\item CUDA C built-in atomic functions
\item Locks and mutex
\item Warps
\item Appendix: the atomic dot product
\end{itemize} $\quad$ \newline

Featured examples: \newline

\begin{itemize}
\item {\tt dot\_product\_atomic\_builtin.cu}
\item {\tt dot\_product\_atomic\_lock.cu}
\item {\tt race\_condition.cu}
\item {\tt race\_condition\_fixed.cu}
\item {\tt blockCounter.cu}
\end{itemize} 


\newpage

\Huge
\begin{center}
{\bf LECTURE SERIES MATERIALS}
\end{center} $\quad$ \newline
\huge
These lecture slides, a tentative syllabus for the whole lecture series, and code are available at: \newline

\begin{center}
 https://github.com/wlandau/gpu. 
\end{center} $\quad$ \newline


After logging into you home directory on impact1, type: \newline

\begin{verbatim}
        git clone https://github.com/wlandau/gpu
\end{verbatim} $\quad$ \newline

into the command line to download all the course materials.


\newpage
\Huge
\begin{center}
{\bf REFERENCES}
\end{center} $\quad$ \newline

NVIDIA CUDA C Programming Guide. Version 3.2. 2010.  \newline

J. Sanders and E. Kandrot. {\it CUDA by Example}. Addison-Wesley, 2010. 


\newpage
\Huge
\begin{center}
{\bf APPENDIX: THE ATOMIC DOT PRODUCT}
\end{center}  \LARGE


\begin{align*}
(a_0, \ a_1, \ldots ,\  a_{15}) \bullet (b_0, \ b_1, \ldots , \ b_{15}) = a_0 b_0 + a_1 b_1 + \cdots + a_{15} b_{15}
\end{align*} $\quad$ \newline
The basic workflow is: \newline

\begin{itemize}
\item Pass vectors {\tt a} and {\tt b} to the GPU. \newline
\item Give each block a sub vector of {\tt a} and the analogous subvector of {\tt b}. 

For the case of 16-element vectors, let there be 2 blocks and 4 threads per block.

\newpage \LARGE
\begin{align*}
\intertext{Block 0 works on:}
&(a_0, a_1, a_2, a_3, \ a_{8}, a_{9}, a_{10}, a_{11}) \\
&(b_0, b_1, b_2, b_3, \ b_{8}, b_{9}, b_{10}, b_{11}) \\
\intertext{Block 1 works on:}
&(a_4,  a_5, a_6, a_7, \ a_{12}, a_{13}, a_{14}, a_{15}) \\
&(b_4,  b_5, b_6, b_7,\  b_{12}, b_{13}, b_{14}, b_{15}) \\
\end{align*}

\item Within each block, compute a vector of partial sums of pairwise products:

\begin{align*}
\intertext{Block 0:}
\text{\tt cache} &= (a_0 \cdot b_0 + a_8 \cdot b_8, \ a_1 \cdot b_1 + a_9 \cdot b_9\ \ldots, \  a_3 \cdot b_3 + a_{11} \cdot b_{11})
\intertext{Block 1:}
\text{\tt cache} &= (a_4 \cdot b_4 + a_{12} \cdot b_{12}, \ a_5 \cdot b_5 + a_{13} \cdot b_{13},\ \ldots, \  a_7 \cdot b_7 + a_{15} \cdot b_{15})
\end{align*}

where {\tt cache} is an array in shared memory. \newline
\item Within each block, compute the pairwise sum of {\tt cache} and write it to {\tt cache[0]}. In our example: 
\begin{align*}
\intertext{Block 0:}
\text{\tt cache[0]} &= a_0 \cdot b_0 + \cdots + a_3 \cdot b_3 + a_8 \cdot b_8 + \cdots +  a_{11} \cdot b_{11}
\intertext{Block 1:}
\text{\tt cache[0]} &= a_4 \cdot b_4 +\cdots +  a_{7} \cdot b_7 + a_{12} \cdot b_{12} + \cdots +  a_{15} \cdot b_{15}
\end{align*} $\quad$ \newpage


\Huge
\begin{center}
{\bf SKIP THESE STEPS:}
\end{center} $\quad \newline$


\color{gray}

\item Fill a new vector in global memory, {\tt partial\_c}, with these partial dot products: 
\begin{align*}
\text{ \tt partial\_c} = (\text{\tt block 0 cache[0]}, \ \text{\tt block 1 cache[0]})
\end{align*} $\quad$ \newline
\item Return to the CPU and compute the linear sum of \text{ \tt partial\_c} and write it to {\tt partial\_c[0]}. Then:

\begin{align*}
\text{\tt partial\_c[0] }= a_0 \cdot b_0 + a_1 \cdot b_1 + \cdots +    a_{15} \cdot b_{15}
\end{align*}
\newpage

\Huge
\begin{center}
{\bf \color{black} INSTEAD:}
\end{center} \quad $\newline$



\item \color{blue} Within {\tt dot()}, ATOMICALLY ADD each block's copy of {\tt cache[0]} to the integer {\tt c}. Then:

\begin{align*}
\text{\tt c }= a_0 \cdot b_0 + a_1 \cdot b_1 + \cdots +    a_{15} \cdot b_{15}
\end{align*}




\end{itemize}

\color{black}




\color{black}
\newpage

\Huge
\begin{center}
{\bf dot\_product\_atomic\_builtin.cu}
\end{center} 

\lstinputlisting[language = C]{dot_product_atomic_builtin.cu}
\newpage

\Huge
\begin{center}
{\bf OUTPUT}
\end{center} $\quad$ \newline

\begin{lstlisting}[language = bash]
[landau@impact1 dot_product_atomic_builtin]$ nvcc dot_product_atomic_builtin.cu -arch sm_20 -o dot
[landau@impact1 dot_product_atomic_builtin]$ ./dot
Does GPU value 2.76217e+22 = 2.76217e+22?
[landau@impact1 dot_product_atomic_builtin]$ 
\end{lstlisting} $\quad$ \newline

Again, if you're using any of the above functions in your code, compile with the flag, {\tt -arch sm\_20} as above. 

\newpage

\color{black}


\LARGE
\begin{center}
{\bf {\tt dot\_product\_atomic\_lock.cu}: THE ATOMIC DOT PRODUCT WITH LOCKS}
\end{center} $\quad$ \newline

\lstinputlisting[language = C]{dot_product_atomic_lock.cu}

\newpage

\Huge
\begin{center}
{\bf OUTPUT}
\end{center} $\quad$ \newline

\begin{lstlisting}[language = bash]
[landau@impact1 dot_product_atomic_lock]$ nvcc dot_product_atomic_lock.cu -arch sm_20 -o dot
[landau@impact1 dot_product_atomic_lock]$ ./dot
Does GPU value 2.76217e+22 = 2.76217e+22?
[landau@impact1 dot_product_atomic_lock]$ 
\end{lstlisting} $\quad$ \newline

NOTE: we still need {\tt -arch sm\_20} because the lock relies on built-in atomic functions.


\end{flushleft}
\end{document}
