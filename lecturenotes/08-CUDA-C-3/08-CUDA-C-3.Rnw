\documentclass{article}

\hoffset = 0pt
\voffset = 0pt
\footskip = 75pt

\usepackage[landscape]{geometry}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{color}
\usepackage{Sweave}
\usepackage{SASnRdisplay}

\providecommand{\beq}{\begin{equation*}}
\providecommand{\eeq}{\end{equation*}}
\providecommand{\bs}{\backslash}
\providecommand{\e}{\varepsilon}
\providecommand{\E}{\ \exists \ }
\providecommand{\all}{\ \forall \ }
\providecommand{\Rt}{\Rightarrow}
\providecommand{\rt}{\rightarrow}
\providecommand{\vc}[1]{\boldsymbol{#1}}
\providecommand{\N}{\mathbb{N}}
\providecommand{\Q}{\mathbb{Q}}
\providecommand{\R}{\mathbb{R}}
\providecommand{\C}{\mathbb{C}}
\providecommand{\Z}{\mathbb{Z}}
\providecommand{\Qn}{\mathbb{Q}^n}
\providecommand{\Rn}{\mathbb{R}^n}
\providecommand{\Cn}{\mathbb{C}^n}
\providecommand{\Zn}{\mathbb{Z}^n}
\providecommand{\Qk}{\mathbb{Q}^k}
\providecommand{\Rk}{\mathbb{R}^k}
\providecommand{\Ck}{\mathbb{C}^k}
\providecommand{\Zk}{\mathbb{Z}^k}
\providecommand{\ov}[1]{\overline{#1}}
\providecommand{\lmu}[1]{\lim_{#1 \rightarrow \infty}}
\providecommand{\lmd}[1]{\lim_{#1 \rightarrow -\infty}}
\providecommand{\lm}[2]{\lim_{#1 \rightarrow #2}}
\providecommand{\nv}{{}^{-1}}
\providecommand{\aut}[1]{\text{Aut}{ \ #1}}
\providecommand{\inn}[1]{\text{Inn}{ \ #1}}
\providecommand{\cj}[1]{\overline{#1}}
\providecommand{\wh}[1]{\widehat{#1}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}

\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}

\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}

\bibliographystyle{plain}

\providecommand{\pset}{1}   %PUT PROBLEM SET NUMBRER HERE
\renewcommand{\labelenumi}{\alph{enumi}.} %controls enumerating style
\renewcommand{\labelenumii}{\roman{enumii}.} 
  
\setcounter{section}{\pset}

\begin{document}
\begin{flushleft}

\Huge
\begin{center}
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
{\bf PERFORMANCE MEASUREMENT AND ATOMICS IN CUDA C}
\end{center} $\quad$ \newline

\LARGE

\begin{center}
Will Landau, Prof. Jarad Niemi
\end{center}

\newpage

\Huge
\begin{center}
{\bf EVENTS: MEASURING PERFORMANCE ON THE GPU}
\end{center} $\quad$ \newline

{\bf Event}: a time stamp for the GPU. \newline

Use events to measure the amount of time the GPU spends on a task. \newline

\newpage



\LARGE

\begin{verbatim}
int main(){
  float   elapsedTime;
  cudaEvent_t start, stop;

  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord( start, 0 );

  // SOME GPU KERNEL YOU WANT TIMED HERE

  cudaEventRecord( stop, 0 );
  cudaEventSynchronize( stop );
  cudaEventElapsedTime( &elapsedTime, start, stop );

  cudaEventDestroy( start );
  cudaEventDestroy( stop ); 

  printf("GPU Time elapsed: %f\n", elapsedTime);
}
\end{verbatim}  \newpage

\Huge

The variable, {\tt elapsedTime}, is the GPU time spent on the task. You can now print it any way you like. \newline
\color{red}

Note: only GPU elapsed time is measured, not CPU time. \newline

GPU time and CPU time must be measured separately.
\color{black}

\newpage

\Huge
\begin{center}
{\bf MEASURING CPU TIME}
\end{center} $\quad$ \newline \huge


\begin{verbatim}
#include <stdio.h>
#include <time.h>

int main(){

  clock_t start = clock();

  // SOME CPU CODE YOU WANT TIMED HERE

  float elapsedTime = ((double)clock() - start) / 
                            CLOCKS_PER_SEC;

  printf("CPU Time elapsed: %f\n", elapsedTime);
}
\end{verbatim} 

\newpage

\Huge
\begin{center}
{\bf RACE CONDITIONS AND ATOMICS}
\end{center} $\quad$ \newline

Consider the following GPU operation on integer {\tt x}: \newline



\begin{verbatim}
                     x++;
\end{verbatim} $\quad$ \newline

which tells the GPU to do 3 things...
\newpage

\begin{verbatim}
                     x++;
\end{verbatim} $\quad$ \newline


\begin{enumerate}[1. ]
\item Read the value stored in x.
\item Add 1 to the value read in step 1.
\item Write the result back to x.
\end{enumerate}


\newpage

Say we need threads A and B to increment x. We want: \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{1} \newpage

but we might get: \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{2} 

\newpage


\Huge
\begin{center}
{\bf EXAMPLE: race\_condition.cu}
\end{center} $\quad$ \newline \large

\begin{verbatim}
#include <stdio.h>
#include <stdlib.h>
#include <cuda.h>
#include <cuda_runtime.h> 

__global__ void colonel(int *a_d){
  *a_d += 1;
}

int main(){

  int a = 0, *a_d;
  
  cudaMalloc((void**) &a_d, sizeof(int));
  cudaMemcpy(a_d, &a, sizeof(int), cudaMemcpyHostToDevice);

  colonel<<<1000,1000>>>(a_d); 
  
  cudaMemcpy(&a, a_d, sizeof(int), cudaMemcpyDeviceToHost);

  printf("a = %d\n", a);
  cudaFree(a_d);

}
\end{verbatim} $\quad$ \newline

\newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{race} \newline \newline

\Huge

Since we started with {\tt a} at 0, we should have gotten {\tt a} = $1000 \cdot 1000$ = 1,000,000.



\newpage


{\bf Race Condition:} A computational hazard that arises when the results of a program depend on the timing of uncontrollable events, such as threads. \newline

{\bf Atomic Operation:} A command that is executed one thread at a time, thus avoiding a race condition. \newline

To avoid the race condition in our example, we atomically add 1 to x: \newline

\begin{verbatim}
               atomicAdd( &x, 1 );
\end{verbatim} $\quad$ \newline

instead of using {\tt x++;}

\newpage

\Huge
\begin{center}
{\bf LIST OF CUDA C BUILT-IN ATOMIC FUNCTIONS}
\end{center} $\quad$ \newline

atomicAdd() \newline
atomicSub()  \newline
atomicMin()  \newline 
atomicMax() \newline
atomicInc() \newline
atomicDec() \newline
atomicExch() \newline
atomicCAS() \newline

\newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{3}  \newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{4} 
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{5} 
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{6}  \newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{7} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{8} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{9} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{10} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{11} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{12} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{13} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{14} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{15} \newpage

\color{red}
\Huge

NOTE: If you're using any of the above functions in your code, compile with the flag, {\tt -arch sm\_20} \newline

Example: \newline
\begin{verbatim}
nvcc dot_product_atomic.cu -arch sm_20 
     -o dot_product_atomic
\end{verbatim}
\newpage

\color{black}

\Huge
\begin{center}
{\bf LOCKS}
\end{center} $\quad$ \newline

{\bf Lock}: a mechanism in parallel computing that forces a block of code to be executed atomically.  \newline

{\bf mutex}: short for ``mutual exclusion", the idea behind locks: while a thread is running code inside a lock, it blocks all other threads from running the code.

\newpage \Large
lock.h: \newline
\setkeys{Gin}{width=.8\textwidth} \includegraphics[scale=0.25,angle=0]{lock} \newpage

\large
Now, let's look at the lock function:

\begin{verbatim}
__device__ void lock( void ) {
    while( atomicCAS( mutex, 0, 1 ) != 0 );
}
\end{verbatim} $\quad$ \newline

In pseudo-code:

\begin{verbatim}
__device__ void lock( void ) {
  repeat{
    do atomically{
      
      if(mutex == 0){
        mutex = 1;
        return_value = 0;
      }
      
      else if(mutex == 1){
        return_value = 1;
      }
      
    } // do atomically
    
    if(return_value = 0)
      exit loop;
    
  } // repeat
}// lock
\end{verbatim} $\quad$ \newpage


\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{lockloop} \newpage




\LARGE
Compare these two kernels, both of which attempt to count the number of spawned blocks: \newline

\begin{verbatim}
__global__ void blockCounterUnlocked( int *nblocks ){
   if(threadIdx.x == 0){
    *nblocks = *nblocks + 1;
  }
}

__global__ void blockCounter1( Lock lock, int *nblocks ){
  if(threadIdx.x == 0){
    lock.lock();
    *nblocks = *nblocks + 1;
    lock.unlock();
  }
}
\end{verbatim} $\quad$ \newline \color{blue}
Which one gives us the correct answer? \newline
Which one is faster?
\color{black}
\newpage

\Huge
\begin{center}
{\bf blockCounter.cu}
\end{center} $\quad$ \newline
\Large
\begin{verbatim}
#include "../common/lock.h"
#define NBLOCKS_TRUE 512
#define NTHREADS_TRUE 512 * 2

__global__ void blockCounterUnlocked( int *nblocks ){
   if(threadIdx.x == 0){
    *nblocks = *nblocks + 1;
  }
}

__global__ void blockCounter1( Lock lock, int *nblocks ){
  if(threadIdx.x == 0){
    lock.lock();
    *nblocks = *nblocks + 1;
    lock.unlock();
  }
}



int main(){
  int nblocks_host, *nblocks_dev;
  Lock lock;
  float elapsedTime;
  cudaEvent_t start, stop;
 
  cudaMalloc((void**) &nblocks_dev, sizeof(int));
  

  //blockCounterUnlocked:

  nblocks_host = 0;
  cudaMemcpy( nblocks_dev, &nblocks_host, sizeof(int), cudaMemcpyHostToDevice );
  
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord( start, 0 );
  
  blockCounterUnlocked<<<NBLOCKS_TRUE, NTHREADS_TRUE>>>(nblocks_dev);

  cudaEventRecord( stop, 0 );
  cudaEventSynchronize( stop );
  cudaEventElapsedTime( &elapsedTime, start, stop );

  cudaEventDestroy( start );
  cudaEventDestroy( stop ); 

  cudaMemcpy( &nblocks_host, nblocks_dev, sizeof(int), cudaMemcpyDeviceToHost );
  printf("blockCounterUnlocked <<< %d, %d >>> () counted %d blocks in %f ms.\n", 
        NBLOCKS_TRUE,
        NTHREADS_TRUE,
        nblocks_host,
        elapsedTime);
        
        
  //blockCounter1:

  nblocks_host = 0;
  cudaMemcpy( nblocks_dev, &nblocks_host, sizeof(int), cudaMemcpyHostToDevice );
  
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
  cudaEventRecord( start, 0 );
  
  blockCounter1<<<NBLOCKS_TRUE, NTHREADS_TRUE>>>(lock, nblocks_dev);

  cudaEventRecord( stop, 0 );
  cudaEventSynchronize( stop );
  cudaEventElapsedTime( &elapsedTime, start, stop );

  cudaEventDestroy( start );
  cudaEventDestroy( stop ); 

  cudaMemcpy( &nblocks_host, nblocks_dev, sizeof(int), cudaMemcpyDeviceToHost );
  printf("blockCounter1 <<< %d, %d >>> () counted %d blocks in %f ms.\n", 
        NBLOCKS_TRUE,
        NTHREADS_TRUE,
        nblocks_host,
        elapsedTime);      
                   
  cudaFree(nblocks_dev); 
}

\end{verbatim}

\newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{locks} \newpage

\Huge
\begin{center}
{\bf WITH MORE THAN 1 THREAD PER BLOCK, THIS KERNEL WILL MAKE YOUR PROGRAM STALL OUT}
\end{center} $\quad$ \newline
 
 \huge
\begin{verbatim}
__global__ void blockCounter2( Lock lock, int *nblocks ){
  lock.lock();
  if(threadIdx.x == 0){
    *nblocks = *nblocks + 1 ;
  }
  lock.unlock();
}
\end{verbatim}

\newpage

\Huge
\begin{center}
{\bf WHY? BECAUSE OF WARPS!}
\end{center} $\quad$ \newline

Each block is divided into groups of 32 threads called warps. \newline

{\bf Warp:} a group of 32 threads that execute together in lockstep: that is, all threads in the warp synchronize after every single step.  \newline

{\color{blue} Imagine that a warp is saturated with calls to {\tt \_\_synchThreads()}.}

\newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{diffwarp} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{samewarp} \newpage
\large
Now, let's look at the lock function again:

\begin{verbatim}
__device__ void lock( void ) {
    while( atomicCAS( mutex, 0, 1 ) != 0 );
}
\end{verbatim} $\quad$ \newline

In pseudo-code:

\begin{verbatim}
__device__ void lock( void ) {
  repeat{
    do atomically{
      
      if(mutex == 0){
        mutex = 1;
        return_value = 0;
      }
      
      else if(mutex == 1){
        return_value = 1;
      }
      
    } // do atomically
    
    if(return_value = 0)
      exit loop;
    
  } // repeat
}// lock
\end{verbatim} $\quad$ \newpage

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{lockloop1} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{lockloop2}  \newpage

\Huge
\begin{center}
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
{\bf BEWARE THE CATCH-22!}
\end{center} $\quad$ \newline



\newpage

\Huge
\begin{center}
{\bf LECTURE SERIES MATERIALS}
\end{center} $\quad$ \newline
\huge
These lecture slides, a tentative syllabus for the whole lecture series, and code are available at: \newline

\begin{center}
 https://github.com/wlandau/gpu. 
\end{center} $\quad$ \newline


After logging into you home directory on impact1, type: \newline

\begin{verbatim}
        git clone https://github.com/wlandau/gpu
\end{verbatim} $\quad$ \newline

into the command line to download all the course materials.



\newpage
\Huge
\begin{center}
{\bf REFERENCES}
\end{center} $\quad$ \newline

NVIDIA CUDA C Programming Guide. Version 3.2. 2010.  \newline

J. Sanders and E. Kandrot. {\it CUDA by Example}. Addison-Wesley, 2010. 


\end{flushleft}
\end{document}