\documentclass{article}

\hoffset = 0pt
\voffset = 0pt
\footskip = 75pt

\usepackage[landscape]{geometry}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{color}
% JBN: Including these two packages would not compile for me. Can you check to see if this file will compile for you as is? If it does, please leave these lines commented out. 
%\usepackage{Sweave}
%\usepackage{SASnRdisplay}

\providecommand{\beq}{\begin{equation*}}
\providecommand{\eeq}{\end{equation*}}
\providecommand{\bs}{\backslash}
\providecommand{\e}{\varepsilon}
\providecommand{\E}{\ \exists \ }
\providecommand{\all}{\ \forall \ }
\providecommand{\Rt}{\Rightarrow}
\providecommand{\rt}{\rightarrow}
\providecommand{\vc}[1]{\boldsymbol{#1}}
\providecommand{\N}{\mathbb{N}}
\providecommand{\Q}{\mathbb{Q}}
\providecommand{\R}{\mathbb{R}}
\providecommand{\C}{\mathbb{C}}
\providecommand{\Z}{\mathbb{Z}}
\providecommand{\Qn}{\mathbb{Q}^n}
\providecommand{\Rn}{\mathbb{R}^n}
\providecommand{\Cn}{\mathbb{C}^n}
\providecommand{\Zn}{\mathbb{Z}^n}
\providecommand{\Qk}{\mathbb{Q}^k}
\providecommand{\Rk}{\mathbb{R}^k}
\providecommand{\Ck}{\mathbb{C}^k}
\providecommand{\Zk}{\mathbb{Z}^k}
\providecommand{\ov}[1]{\overline{#1}}
\providecommand{\lmu}[1]{\lim_{#1 \rightarrow \infty}}
\providecommand{\lmd}[1]{\lim_{#1 \rightarrow -\infty}}
\providecommand{\lm}[2]{\lim_{#1 \rightarrow #2}}
\providecommand{\nv}{{}^{-1}}
\providecommand{\aut}[1]{\text{Aut}{ \ #1}}
\providecommand{\inn}[1]{\text{Inn}{ \ #1}}
\providecommand{\cj}[1]{\overline{#1}}
\providecommand{\wh}[1]{\widehat{#1}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}

\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}

\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}

\bibliographystyle{plain}

\providecommand{\pset}{1}   %PUT PROBLEM SET NUMBRER HERE
\renewcommand{\labelenumi}{\alph{enumi}.} %controls enumerating style
\renewcommand{\labelenumii}{\roman{enumii}.} 
  
\setcounter{section}{\pset}

\begin{document}
\begin{flushleft}

\Huge
\begin{center}
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
$\quad$ \newline
{\bf CUDA C: THE SIMD PARADIGM, SHARED MEMORY, AND THE DOT PRODUCT}
\end{center} $\quad$ \newline

\LARGE

\begin{center}
Will Landau, Prof. Jarad Niemi
\end{center}

\newpage

\Huge
\begin{center}
{\bf OUTLINE} 
\end{center} $\quad$ \newline \Large
\begin{itemize}
\item Respecting the SIMD paradigm
\item Shared memory
\item Implementing the dot product
\end{itemize} $\quad$ \newline

Featured examples: \newline
\begin{itemize}
\item {\tt dot\_product.cu}
\end{itemize}
% JBN: Last time we discussed providing pseudo-C-code. Perhaps it would make sense to included pseudo-C-code for the dot-product since you are going to be using it in this lecture. 

\newpage




\Huge
\begin{center}
{\bf THE SIMD PARADIGM}
\end{center} $\quad$ \newline

{\bf SIMD}: Single Instruction Multiple Data \newline

Each thread uses the same code, but applies it to different data.  \newline

Try to respect this paradigm in your code. If multiple threads access the same data, problems could arise.



\newpage
\Huge
\begin{center}
{\bf EXAMPLE}
\end{center} 

 \LARGE
Let's say we have a kernel: \newline

\begin{verbatim}
    __global__ void kernel(void){
      int x = blockIdx.x;
    }
\end{verbatim} $\quad$ \newline
\setkeys{Gin}{width=.5\textwidth} \includegraphics[scale=0.25,angle=0]{share} \newline

What will be the final value of x?
% JBN: x is shared in local memory and is specific to each thread, so this question is non-sensical. Perhaps instead you want something like 
%     __global__ void kernel(int *x){
%      *x = blockIdx.x;
% where x has previously been allocated in global memory through a cudaMalloc statement. 

\newpage

\huge

All the threads in the grid share the same copy of {\tt a} in {\color{blue} GLOBAL MEMORY}.
\newline

Hence, the final value of {\tt x} is the block ID of the thread that finishes last.





\newpage
\Huge
\begin{center}
{\bf GLOBAL VS SHARED MEMORY}
\end{center} 
\setkeys{Gin}{width=0.7\textwidth} \includegraphics[scale=0.25,angle=0]{mem} \newline
\huge

Why not give each block its own private copy of {\tt x} in shared memory? 
% JBN: As pointed out earlier. The previous copy of x is in local memory so it is private.


\newpage
\Large
If we define: \newline

\begin{verbatim}
    __global__ void kernel(void){
      __shared__ int x = blockIdx.x;
    }
\end{verbatim} $\quad$ \newline

then each BLOCK will have its own copy of x in {\color{blue} SHARED MEMORY}, shared by all the threads in the block.  \newline \newline

If we call: \newline

\begin{verbatim}
    kernel<<6, 1>>();
\end{verbatim} $\quad$ \newline

Then the final values of $x$ will ALWAYS be: \newline

\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 &  Block 0 & Block 1 & Block 2 & Block 3 & Block 4 & Block 5 \\ \hline
Thread 0 & x = 0 & x = 1 & x = 2 & x = 3 & x = 4 & x = 5 \\ \hline
\end{tabular} $\quad$ \newline \newline
% JBN: This will have problems if you change blockIdx.x to threadIdx.x and have more than 1 thread in the block. Actually since the number of threads is always rounded up to the nearest warp,  I don't know if it will even work with 1 thread in the block.

\newpage

\huge
\begin{center}
{\bf NOW, WE'RE READY FOR THE DOT PRODUCT}
\end{center} $\quad$ \newline

\begin{align*}
(x_1, \ x_2, \ x_3,\  x_4) \bullet (y_1, \ y_2, \ y_3, \ y_4) = x_1 y_1 + x_2 y_2 + x_3 y_3 + x_4 y_4
\end{align*} $\quad$ \newline


\newpage

First part of the code: \newline

\setkeys{Gin}{width=.73\textwidth} \includegraphics[scale=0.25,angle=0]{c1} 
\setkeys{Gin}{width=.47\textwidth} \includegraphics[scale=0.25,angle=0]{c2} \newpage
% JBN: Why are these graphics files? Wouldn't it be better to have them as plain text? 
% JBN: Why do we have the imin function?
% JBN: Make sure to point out here that a and b are passed from the CPU. Each block will take a sub-vector of a and the associated subvector of b, calculate the dot-product of these sub-vectors, and return the scalar as one element of the vector c. 
% JBN: Pedagogically, it is a big jump from do the dot product to this code. Perhaps it would be good to build the code up rather than starting with the entire code and deconstructing. 
% JBN: I think you need another slide here describing the procedure you plan on implementing in pseudo-code. 
What the code does: \newline \newline \newline

% JBN: I don't see the dot<<2,4>>(a,b,c) line on the previous slide.
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w0} \newpage
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w1} \newpage
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w2} \newpage
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w3} \newpage
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w4} \newpage
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w5} \newpage
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w6} \newpage
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w7} \newpage
\setkeys{Gin}{width=1.15\textwidth} \includegraphics[scale=0.25,angle=0]{w8} \newpage


We want to make sure that {\tt cache} is filled up for each block before we continue further. \newline
% JBN: "filled up for each block" -> "filled up within each block"

Hence, the next line of code is: \newline \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{synch} 

\newpage

\Huge
\begin{center}
{\bf NEXT, WE EXECUTE A PAIRWISE SUM ON {\tt cache} FOR EACH BLOCK}
\end{center} $\quad$ \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{step2} \newpage



\Huge
\begin{center}
{\bf WHAT'S GOING ON}
\end{center} $\quad$ \newline


\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{s1} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{s2} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{s3} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{s4} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{s5} \newpage
\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{s6} 

Similarly, the contribution of block 1 to the dot product is 183.

Next: \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{mess} \newline


So now, c[0] = 123 and c[1] is 183. \newline

We return c to the cpu, call it {\tt partial\_c} and then take a linear sum of the elements of {\tt partial\_c}: \newline
% JBN: This is confusing because of the renaming. Why not just call it partial_c in the original code. Perhaps elaborate that c holds the dot product for the block's sub-vectors. 

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{final} \newline



Now, c is the final answer.

\newpage

\Huge
\begin{center}
{\bf COMPLETE CODE}
\end{center}



\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{comp1} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{comp2} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{comp3} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{comp4} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{comp5} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{comp6} \newpage
% JBN: I was confusing by their comparison to the sum of squares formula because I forgot C is zero-based indexing. So I thought it should be sum_squares(N). Just wanted to point it out in case anybody else is confused. 

\newpage

\Huge
\begin{center}
{\bf OUTLINE} 
\end{center} $\quad$ \newline \Large
\begin{itemize}
\item Respecting the SIMD paradigm
\item Shared memory
\item Implementing the dot product
\end{itemize} $\quad$ \newline

Featured examples: \newline
\begin{itemize}
\item {\tt dot\_product.cu}
\end{itemize}

\newpage

\Huge
\begin{center}
{\bf LECTURE SERIES MATERIALS}
\end{center} $\quad$ \newline
\huge
These lecture slides, a tentative syllabus for the whole lecture series, and code are available at: \newline

\begin{center}
 https://github.com/wlandau/gpu. 
\end{center} $\quad$ \newline


After logging into you home directory on impact1, type: \newline

\begin{verbatim}
        git clone https://github.com/wlandau/gpu
\end{verbatim} $\quad$ \newline

into the command line to download all the course materials.


\newpage
\Huge
\begin{center}
{\bf REFERENCES}
\end{center} $\quad$ \newline

David B. Kirk and Wen-mei W. Hwu. ``Programming Massively Parallel Processors: a Hands-on Approach." Morgan Kaufman, 2010. \newline

J. Sanders and E. Kandrot. {\it CUDA by Example}. Addison-Wesley, 2010. \newline

Michael Romero and Rodrigo Urra. "CUDA Programming."  Rochester Institute of Technology. http://cuda.ce.rit.edu/cuda\_overview/cuda\_overview.html

\end{flushleft}
\end{document}

