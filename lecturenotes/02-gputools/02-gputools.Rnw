\documentclass{article}

\hoffset = 0pt
\voffset = 0pt
\footskip = 75pt

\usepackage[landscape]{geometry}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{color}
\usepackage{Sweave}
\usepackage{SASnRdisplay}

\providecommand{\beq}{\begin{equation*}}
\providecommand{\eeq}{\end{equation*}}
\providecommand{\bs}{\backslash}
\providecommand{\e}{\varepsilon}
\providecommand{\E}{\ \exists \ }
\providecommand{\all}{\ \forall \ }
\providecommand{\Rt}{\Rightarrow}
\providecommand{\rt}{\rightarrow}
\providecommand{\vc}[1]{\boldsymbol{#1}}
\providecommand{\N}{\mathbb{N}}
\providecommand{\Q}{\mathbb{Q}}
\providecommand{\R}{\mathbb{R}}
\providecommand{\C}{\mathbb{C}}
\providecommand{\Z}{\mathbb{Z}}
\providecommand{\Qn}{\mathbb{Q}^n}
\providecommand{\Rn}{\mathbb{R}^n}
\providecommand{\Cn}{\mathbb{C}^n}
\providecommand{\Zn}{\mathbb{Z}^n}
\providecommand{\Qk}{\mathbb{Q}^k}
\providecommand{\Rk}{\mathbb{R}^k}
\providecommand{\Ck}{\mathbb{C}^k}
\providecommand{\Zk}{\mathbb{Z}^k}
\providecommand{\ov}[1]{\overline{#1}}
\providecommand{\lmu}[1]{\lim_{#1 \rightarrow \infty}}
\providecommand{\lmd}[1]{\lim_{#1 \rightarrow -\infty}}
\providecommand{\lm}[2]{\lim_{#1 \rightarrow #2}}
\providecommand{\nv}{{}^{-1}}
\providecommand{\aut}[1]{\text{Aut}{ \ #1}}
\providecommand{\inn}[1]{\text{Inn}{ \ #1}}
\providecommand{\cj}[1]{\overline{#1}}
\providecommand{\wh}[1]{\widehat{#1}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}

\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}

\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}

\bibliographystyle{plain}

\providecommand{\pset}{1}   %PUT PROBLEM SET NUMBRER HERE
\renewcommand{\labelenumi}{\alph{enumi}.} %controls enumerating style
\renewcommand{\labelenumii}{\roman{enumii}.} 

\setcounter{section}{\pset}

\begin{document}
\begin{flushleft}

\Huge
\begin{center}

$\quad$ \newline \newline \newline \newline \newline

{\bf gputools: an R package for GPU computing} \newline \newline

\Large

Will Landau, Prof. Jarad Niemi
\end{center} $\quad$ \newline
\newpage

\Huge
\begin{center}
{\bf Outline}
\end{center} $\quad$ \newline

\begin{itemize}
\item Contents of gputools
\item Usage
\item Performance
\item Other R packages for the GPU
\end{itemize}

\newpage

\Huge
\begin{center}
{\bf CONTENTS OF gputools}
\end{center}  \LARGE

A handful of selected R functions implemented with CUDA C for use on a GPU: \newline

\begin{itemize}
\item Choose your device: \newline

\begin{tabular}{r|l|c}

 \bf gputools function & \bf CPU analog  & \bf Same usage? \\ \hline
chooseGpu() & none & NA \\
getGpuId() & none & NA
\end{tabular} $\quad$ \newline


\item Linear algebra: \newline
\begin{center}
\begin{tabular}{r|l|c}

 \bf gputools function & \bf CPU analog  & \bf Same usage? \\ \hline
gpuDist() & dist() & no \\ 
gpuMatMult() & \%*\% operator & no \\ 
gpuCrossprod() & crossprod() & yes \\ 
gpuTcrossprod() & tcrossprod() & yes \\ 
gpuQr() & qr() & almost \\ 
gpuSolve() & solve() & no \\ 
gpuSvd() & svd() & almost \\ 
\end{tabular}
\end{center}

\newpage

\item Simple model fitting: \newline
\begin{center}
\begin{tabular}{r|l|c}

 \bf gputools function & \bf CPU analog  & \bf Same exact usage? \\ \hline
gpuLm() & lm() & yes \\ 
gpuLsfit() & lsfit() & yes \\ 
gpuGlm() & glm() & yes \\
gpuGlm.fit() & glm.fit() & yes \\ 
\end{tabular} $\quad$ \newline
\end{center}

\item Hypothesis testing: \newline

\begin{center}
\begin{tabular}{r|l|c}
 \bf gputools function & \bf CPU analog  & \bf Same exact usage? \\ \hline
gpuTtest() & t.test() & no \\ 
getAucEstimate() & ??? & ??? \\
\end{tabular} $\quad$ \newline
\end{center}


\newpage
\item Other routines: \newline

\begin{center}
\begin{tabular}{r|l|c}
\bf gputools function & \bf CPU analog  & \bf Same exact usage? \\ \hline
gpuHclust() & hclust() & no \\
gpuDistClust() & hclust(dist()) & no \\ 
gpuFastICA() & fastICA() (fastICA package) & yes \\
gpuGranger() & grangertest() (lmtest package) & no \\
gpuMi() & ??? & ??? \\
gpuSvmPredict() & See www.jstatsoft.org/v15/i09/paper & no \\
gpuSvmTrain() & See www.jstatsoft.org/v15/i09/paper & no \\
\end{tabular}
\end{center}
\end{itemize}


\newpage

\Huge
\begin{center}
{\bf getAucEstimate()}
\end{center} $\quad$ \newline \huge

Estimates the area under a receiver operating characteristic (ROC) curve. \newline

Used to evaluate the performance of a hypothesis test in a multiple testing scenario. \newline

Reference:  \newline

Hand, David J. and Till, Robert J. (2001). A simple generalisation of the area under the ROC curve
for multiple class classification problems. Machine Learning. 45, 171-186.

\newpage

\Huge
\begin{center}
{\bf gpuHclust()}
\end{center} $\quad$ \newline

Performs hierarchical clustering on a set of points.  \newline

The distances among the points must be given in an bject of class "dist".

\newpage

\Huge
\begin{center}
{\bf gpuDistClust()}
\end{center} $\quad$ \newline

Given a set of points, computes all pairwise distances and then performs hierarchical clustering on the points. \newline

Both steps are done on the GPU.
\newpage

\Huge
\begin{center}
{\bf gpuFastICA}
\end{center} $\quad$ \newline \LARGE

Performs Independent Component Analysis (ICA) and Projection Pursuit. \newline

ICA, like principle component analysis, is a linear decomposition of a design matrix. \newline

The authors of fastICA claim that, unlike PCA, ICA ``unmixes" the underlying sources of variability in the data by assuming a non-Gaussian structure. \newline

This function is exactly like the ICA implementation in the {\tt fastICA} package except that the {\tt gputools} version uses {\tt gpuSvd()} instead of {\tt svd()}. \newline

\large
References: \newline

A. Hyvarinen and E. Oja (2000) Independent Component Analysis: Algorithms and Applications,
Neural Networks, 13(4-5):411-430. http://www.cis.hut.fi/aapo/ \newline

A. Hyvarinen. Independent Component Analysis: Recent Advances. Philosophical Transactions of the Royal Society A, in press. http://www.cs.helsinki.fi/u/ahyvarin/papers/PTRSA12.pdf.

\newpage

\Huge
\begin{center}
{\bf gpuGranger()}
\end{center} $\quad$ \newline 

Performs the Granger Causality Test, which tests how well one time series forecasts another. \newline

Reference: \newline

Hacker R.S. and Hatemi-J A. (2006) "Tests for causality between integrated variables using asymptotic and bootstrap distributions: theory and application", Applied Economics, Vol. 38(13), pp. 1489-1500.
\newpage


\Huge
\begin{center}
{\bf gpuMi()}
\end{center} $\quad$ \newline \huge

Estimates the mutual information for pairs of vectors using a B spline approach. \newline

Reference: \newline

Carten O. Daub, Ralf Steuer, Joachim Selbig, and Sebastian Kloska. 2004. Estimating mutual information using B-spline functions - an improved similarity measure for analysing gene expression
data. BMC Bioinformatics. 5:118. Available from http://www.biomedcentral.com/1471-2105/5/118
\newpage

\Huge
\begin{center}
{\bf gpuSvmPredict()}
\end{center} $\quad$ \newline \huge

Classifies points in a data set using a support vector machine. \newline

In machine learning, support vector machine (SVM) is a learning model used for classification and regression. \newline

Reference: \newline

Carpenter, Austin. cuSVM: a cuda implementation of support vector classification and regression.
http://patternsonascreen.net/cuSVM.html

\newpage 

\Huge
\begin{center}
{\bf gpuSvmTrain()}
\end{center} $\quad$ \newline \huge

Trains a support vector machine.  \newline

Reference: \newline

Carpenter, Austin. cuSVM: a cuda implementation of support vector classification and regression.
http://patternsonascreen.net/cuSVM.html
\newpage

\huge
\begin{center}
{\bf USAGE}
\end{center}  \huge

\begin{itemize}
\item gputools is already installed on impact1.stat.iastate.edu, ready to load with {\tt library(gputools)} in R.
\item For other GPU systems, download gputools from CRAN with a simple {\tt install.packages("gputools")} in R. 
\begin{itemize}
\item {\color{red} WARNING: installation will fail on non-GPU systems since the CUDA C compiler doesn't exist}
\end{itemize}
\item Documentation:
\begin{itemize}
\item http://brainarray.mbni.med.umich.edu/Brainarray/Rgpgpu/
\item http://cran.r-project.org/web/packages/gputools/index.html
\item http://cran.r-project.org/web/packages/gputools/gputools.pdf
\end{itemize}
\item Requirements:
\begin{itemize}
\item R (>= version 2.8.0)
\item Nvidia's CUDA toolkit (>= version 2.3)
\end{itemize}
\end{itemize}



\newpage
\huge
\begin{center}
{\bf MANAGING YOUR DEVICES: {\tt chooseGpu()} AND {\tt getGpuId()}}
\end{center} $\quad$ \newline

Impact1 has four GPUs, each with a unique index from 0 to 3. To see this for yourself, log into impact1 and run the following: \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{picts/0} \newline

Here are some pieces of the (quite verbose) output of {\tt ./deviceQuery}: \newline \Huge

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{picts/1} \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{picts/2} \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{picts/3} \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{picts/4} \newline


Things to note: \newline

\begin{itemize}
\item Device 3 is a GPU
\item ``Tesla M2070'' is the name of the model of the GPU. 
\item Device 3 contains multiple cores, or ``sub-processors''. From the output, it has 448 CUDA-capable cores.
\end{itemize}

\newpage

\Huge
\begin{center}
{\bf nvidia-smi: CHECK GPU USAGE BEFORE {\tt chooseGpu()} }
\end{center} 

\setkeys{Gin}{width=.8\textwidth} \includegraphics[scale=0.25,angle=0]{picts/nvidia-smi1} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/nvidia-smi2} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/nvidia-smi3} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/nvidia-smi4} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/nvidia-smi5} \newpage





\newpage
\color{black}
\Huge
\begin{center}
{\bf EXAMPLE: MATRIX MULTIPLICATION}
\end{center} $\quad$ \newline

Now, suppose I want to do a giant matrix multiplication on Device 3. I'm automatically set to Device 0: \newline

% JBN:Can an available GPU be automatically selected?

\setkeys{Gin}{width=.3\textwidth} \includegraphics[scale=0.25,angle=0]{picts/6} \newline

So I change to Device 3: \newline

\setkeys{Gin}{width=.3\textwidth} \includegraphics[scale=0.25,angle=0]{picts/7} \newline

and then if I want, I can verify the change: \newline

\setkeys{Gin}{width=.3\textwidth} \includegraphics[scale=0.25,angle=0]{picts/8} \newline



Now, I define the matrices that I want to multiply on Device 3: \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{picts/5} \newline

\newpage

Then, I tell the device to multiply {\tt A} and {\tt B} using the GPU hardware:  \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{picts/9} \newline

Compare the run time to that of the analogous CPU run on impact1: \newline

\setkeys{Gin}{width=1.1\textwidth} \includegraphics[scale=0.25,angle=0]{picts/10} \newpage



\Huge
\begin{center}

$\quad$ \newline \newline \newline \newline \newline

{\bf $\qquad \quad$ PERFORMANCE} \newline \newline

\end{center} $\quad$ \newline
\newpage

\newpage
\Huge
\begin{center}
{\bf A COMPARISON OF gpuQr() AND qr()}
\end{center} $\quad$ \newline

The R script, {\tt gpuQr.r}, compares the performance of {\tt gpuQr(arg)} and {\tt qr(arg)} for square matrices {\tt arg} of varying sizes. \newline

 See the results on the next few slides. \newline

\newpage

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuQr_user_small} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuQr_syst_small} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/qrsmall} \newpage

\newpage

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuQr_user_large} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuQr_syst_large} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/qrbig} \newpage

% JBN: I think this final graph is sufficient


\Huge
\begin{center}
{\bf A COMPARISON OF gpuSolve() AND solve()}
\end{center} $\quad$ \newline

The R script, {\tt gpuSolve.r}, compares the performance of {\tt gpuSolve(arg)} and {\tt solve(arg)} for square matrices {\tt arg} of varying sizes. \newline

 See the results on the next slide. \newline

\newpage

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuSolve_user_small} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuSolve_syst_small} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/solve} \newpage

\newpage

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuSolve_user_large} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuSolve_syst_large} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuSolve_total_large} \newpage




\newpage

% JBN: were the following not impressive? 
%      if they were, I would prefer to see one graph for each operation, i.e. QR, SVD, LM, GLM
%      what about t-test? It might be interesting to see this example since on slide 4 you mention the usage is different

%\Huge
%\begin{center}
%{\bf A COMPARISON OF gpuSvd() AND svd()}
%\end{center} $\quad$ \newline

%The R script, {\tt gpuSvd.r}, compares the performance of {\tt gpuSvd(x)} and {\tt svd(x)} for matrices {\tt x} of varying sizes. See the results on the next few slides.

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{performance_gpuSvd_user} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{performance_gpuSvd_syst} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{performance_gpuSvd_total} \newpage
% \newpage


\Huge
\begin{center}
{\bf A COMPARISON OF gpuLm() AND lm()}
\end{center} $\quad$ \newline

The R script, {\tt gpuLm.r}, compares the performance of {\tt gpuLm(y $\sim$ X)} and {\tt lm(y $\sim$ X)}, where: \newline

\begin{itemize}
\item {\tt y} is a random vector of observations. 
\item {\tt X} is a random design matrix with {\tt length(y)} rows and 100 columns.
\end{itemize}  $\quad$ \newline
The script times each function with varying {\tt length(y)} and {\tt nrow(X)}. \newline

See the results on the next slides.

\newpage

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuLm_user_small} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuLm_syst_small} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/lmsmall} \newpage


\newpage

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuLm_user_large} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuLm_syst_large} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/lmbig} \newpage



\Huge
\begin{center}
{\bf A COMPARISON OF gpuGlm() AND glm()}
\end{center} $\quad$ \newline \huge

The R script, {\tt gpuGlm.r}, compares the performance of {\tt gpuGlm(y $\sim$ X, family = poisson())} and {\tt glm(y $\sim$ X, family = poisson())}, where: \newline

\begin{itemize}
\item {\tt y} is a random vector of observations. 
\item {\tt X} is a random design matrix with {\tt length(y)} rows and 100 columns.
\end{itemize}  $\quad$ \newline
The script times each function with varying {\tt length(y)} and {\tt nrow(X)}. \newline

See the results on the next slides.

\newpage

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuGlm_user_small} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuGlm_syst_small} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/glmsmall} \newpage


\newpage

%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuGlm_user_large} \newpage
%\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/performance_gpuGlm_syst_large} \newpage
\setkeys{Gin}{width=.9\textwidth} \includegraphics[scale=0.25,angle=0]{picts/glmbig} \newpage


\Huge
\begin{center}
{\bf CLAIMS FROM THE AUTHORS OF {\tt gputools}}
\end{center} $\quad$ \newline

(All of the following is from http://brainarray.mbni.med.umich.edu/Brainarray/Rgpgpu/.) \newline

``Tested on a subset of GSE6306, non-GPU enabled fastICA took over four hours while gpuFastICA took just 80 seconds!"

\newpage

\setkeys{Gin}{width=.7\textwidth} \includegraphics[scale=0.25,angle=0]{picts/11} 


\newpage

\setkeys{Gin}{width=.7\textwidth} \includegraphics[scale=0.25,angle=0]{picts/12} 

\newpage

\setkeys{Gin}{width=.7\textwidth} \includegraphics[scale=0.25,angle=0]{picts/13} 

\newpage

\setkeys{Gin}{width=.7\textwidth} \includegraphics[scale=0.25,angle=0]{picts/14} 

\newpage

\Huge
\begin{center}
{\bf OTHER R PACKAGES FOR THE GPU}
\end{center} $\quad$ \newline


\begin{itemize}
\item WideLM - used to quickly fit a large number of linear models to a fixed design matrix and response vector.
\item magma - a small linear algebra with implementations of backsolving and the LU factorization.
\item cudaBayesreg - implements a Bayesian model for fitting fMRI data. 
\item gcbd - a Debian package for ``benchmarking" linear algebra algorithms such as the QR, SVD and LU factorizations.
\end{itemize}

\newpage

\Huge
\begin{center}
{\bf Outline}
\end{center} $\quad$ \newline

\begin{itemize}
\item Contents of gputools
\item Usage
\item Performance
\item Other R packages for the GPU
\end{itemize}


\newpage
\Huge
\begin{center}
{\bf GPU SERIES MATERIALS}
\end{center} $\quad$ \newline
\huge
These slides, a tentative syllabus for the whole series, and code are available at: \newline

\begin{center}
 https://github.com/wlandau/gpu. 
\end{center} $\quad$ \newline


After logging into you home directory on impact1, type: \newline

\begin{verbatim}
        git clone https://github.com/wlandau/gpu
\end{verbatim} $\quad$ \newline

into the command line to download all the materials.

\newpage

\Huge
\begin{center}
{\bf REFERENCES}
\end{center} $\quad$ \newline \Large

Josh Buckner, Mark Seligman, Justin Wilson. ``R+GPU". http://brainarray.mbni.med.umich.edu/Brainarray/Rgpgpu/\#introduction. \newline

Carten O. Daub, Ralf Steuer, Joachim Selbig, and Sebastian Kloska. 2004. Estimating mutual information using B-spline functions - an improved similarity measure for analysing gene expression data. BMC Bioinformatics. 5:118. Available from http://www.biomedcentral.com/1471-2105/5/118 \newline

Carpenter, Austin. cuSVM: a cuda implementation of support vector classification and regression.
http://patternsonascreen.net/cuSVM.html \newline

Dirk Eddelbuettel. ``Package gcbd". http://cran.r-project.org/web/packages/gcbd/gcbd.pdf. \newline

Hacker R.S. and Hatemi-J A. (2006) "Tests for causality between integrated variables using asymptotic and bootstrap distributions: theory and application", Applied Economics, Vol. 38(13), pp. 1489-1500. \newline

Hand, David J. and Till, Robert J. (2001). A simple generalisation of the area under the ROC curve
for multiple class classification problems. Machine Learning. 45, 171-186. \newline

A. Hyvarinen and E. Oja (2000) Independent Component Analysis: Algorithms and Applications,
Neural Networks, 13(4-5):411-430. http://www.cis.hut.fi/aapo/ \newline

A. Hyvarinen. Independent Component Analysis: Recent Advances. Philosophical Transactions of the Royal Society A, in press. http://www.cs.helsinki.fi/u/ahyvarin/papers/PTRSA12.pdf. \newline

Mark Seligman, Chris Fraley. ``Package WideLM". http://cran.r-project.org/web/packages/WideLM/WideLM.pdf. \newline

Brian J Smith. ``Package cudaBayesreg". http://cran.r-project.org/web/packages/cudaBayesreg/cudaBayesreg.pdf.

\end{flushleft}
\end{document}
